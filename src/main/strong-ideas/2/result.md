Для исследования мной были выбраны микросервисы из рабочего проекта, написанные на языке Java и Kotlin, на базе фреймворка Spring. Опишу специфику выбранных микросервисов:
1) много интеграций с внешними сервисами
2) простые алгоритмы работы, которые преимущественно заключаются в агрегации ответов внешних сервисов

Для организации fuzzing-тестирования была выбрана утилита jazzer https://github.com/CodeIntelligenceTesting/jazzer. Почему обратил внимание на этот проект?
1) подходит для тестирования Java и Kotlin приложений
2) кодовая база активно дорабатывается
3) есть простая интеграция в maven/gradle проект c JUnit 5 (для версий 5.9.+)
4) тестируемый код инструментируется, что положительно сказывается на полноте его покрытия 

С какими трудностями я столкнулся при организации fuzzing-тестирования?
1) Написание тестов для логики приложения, основанной преимущественно на взаимодействии с сервисами, более трудоёмко, чем написание интеграционных и юнит-тестов: нужно не только мокать вызовы, но и эффективно внедрять в их результаты фазз-данные.
2) Методы, которые возвращают неразличимые сообщения об ошибке, не могут быть протестированы.
3) Чтобы отличить ожидаемые ошибки от незапланированных, часто требуется написать в тесте длинный список игнорируемых исключительных ситуаций.
4) Выполнение тестов ресурсоемко и может занимать значительное время.

Какие результаты удалось получить?
С помощью fuzzing-тестирования мне не удалось найти ни одной ошибки в исследуемых микросервисах. Это обусловлено спецификой исследуемых проектов. Кроме того, тестирование методов с большим числом аргументов или с аргументами с большим числом состояний приводило к OutOfMemoryError. Я не успел разобраться с причиной, связана ли ошибка с несовершенством библиотеки или малым количеством ресурсов.

Также отмечу, что написание тестов (с непривычки) достаточно трудоемко и требует высокой концентрации, а также тщательного планирования. Если к этому процессу не подойти ответственно, то бОльшая часть тестов будет "спотыкаться" об условия и логику приложения, которая ожидает данные по определенному контракту.

В то же время ошибки, сгенерированные в коде мной самостоятельно, благодаря инструментированию были успешно найдены.

Выводы
Fuzzing-тестирование — ресурсоемкий подход к тестированию, который можно эффективно использовать на достаточно узком спектре задач.

Какие рекомендации я бы мог дать тем, кто хочет применить его на своем проекте? 
1) Вы должны определить точки входа, которые будут подвергаться fuzzing-тестированию. В моем кейсе, на первый взгляд, хорошей идеей выглядело написание интеграционных тестов для контроллеров, т.е. тестирование пути от получения запроса микросервисом до передачи ответа наружу. Сделать это достаточно проблематично, так как требует глубокой проработки тестовых сценариев, иначе можно получить низкое покрытие тестируемого кода. Необходимо предварительно изучить приложение и выявить уязвимые места, такие как парсеры данных, работу с сетевыми протоколами или пользовательским вводом, для которых данный подход будет наиболее эффективен. 
2) Для сокращения времени разработки тестовых сценариев в части генерации качественных тестовых данных может помочь инструментирование кода (если ваше решение его предоставляет).
3) При изменении контрактов методов в тестируемом коде, которое может происходить в том числе неявно (например, новая версия библиотеки начала бросать новое непроверяемое исключение), потребуется правка тестов.
